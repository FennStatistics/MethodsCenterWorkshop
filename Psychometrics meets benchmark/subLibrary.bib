% Encoding: UTF-8
@article{speckBiomimeticBioinspiredBiomorph2017,
  title = {Biomimetic Bio-Inspired Biomorph Sustainable? {{An}} Attempt to Classify and Clarify Biology-Derived Technical Developments},
  shorttitle = {Biomimetic Bio-Inspired Biomorph Sustainable?},
  author = {Speck, Olga and Speck, David and Horn, Rafael and Gantner, Johannes and Sedlbauer, Klaus Peter},
  year = {2017},
  month = jan,
  journal = {Bioinspiration \& Biomimetics},
  volume = {12},
  number = {1},
  pages = {011004},
  publisher = {IOP Publishing},
  issn = {1748-3190},
  doi = {10.1088/1748-3190/12/1/011004},
  urldate = {2024-06-04},
  abstract = {Over the last few decades, the systematic approach of knowledge transfer from biological concept generators to technical applications has received increasing attention, particularly because marketable bio-derived developments are often described as sustainable. The objective of this paper is to rationalize and refine the discussion about bio-derived developments also with respect to sustainability by taking descriptive, normative and emotional aspects into consideration. In the framework of supervised learning, a dataset of 70 biology-derived and technology-derived developments characterised by 9 different attributes together with their respective values and assigned to one of 17 classes was created. On the basis of the dataset a decision tree was generated which can be used as a straightforward classification tool to identify biology-derived and technology-derived developments. The validation of the applied learning procedure achieved an average accuracy of 90.0\%. Additional extraordinary qualities of technical applications are generally discussed by means of selected biology-derived and technology-derived examples with reference to normative (contribution to sustainability) and emotional aspects (aesthetics and symbolic character). In the context of a case study from the building sector, all aspects are critically discussed.},
  langid = {english},
  file = {C:\Users\fenn\Zotero\storage\A9A8ZLH4\Speck et al. - 2017 - Biomimetic bio-inspired biomorph sustainable An a.pdf}
}
@article{jacobucciPracticalGuideVariable2019,
  title = {A {{Practical Guide}} to {{Variable Selection}} in {{Structural Equation Modeling}} by {{Using Regularized Multiple-Indicators}}, {{Multiple-Causes Models}}},
  author = {Jacobucci, Ross and Brandmaier, Andreas M. and Kievit, Rogier A.},
  year = {2019},
  month = mar,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {1},
  pages = {55--76},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245919826527},
  urldate = {2022-11-26},
  abstract = {Methodological innovations have allowed researchers to consider increasingly sophisticated statistical models that are better in line with the complexities of real-world behavioral data. However, despite these powerful new analytic approaches, sample sizes may not always be sufficiently large to deal with the increase in model complexity. This difficult modeling scenario entails large models with a limited number of observations given the number of parameters. Here, we describe a particular strategy to overcome this challenge: regularization, a method of penalizing model complexity during estimation. Regularization has proven to be a viable option for estimating parameters in this small-sample, many-predictors setting, but so far it has been used mostly in linear regression models. We show how to integrate regularization within structural equation models, a popular analytic approach in psychology. We first describe the rationale behind regularization in regression contexts and how it can be extended to regularized structural equation modeling. We then evaluate our approach using a simulation study, showing that regularized structural equation modeling outperforms traditional structural equation modeling in situations with a large number of predictors and a small sample size. Next, we illustrate the power of this approach in two empirical examples: modeling the neural determinants of visual short-term memory and identifying demographic correlates of stress, anxiety, and depression.},
  langid = {english},
  file = {C:\Users\fenn\Zotero\storage\RJS9HPK2\Jacobucci et al. - 2019 - A Practical Guide to Variable Selection in Structu.pdf}
}

@misc{jacobucciRegsemRegularizedStructural2017,
  title = {Regsem: {{Regularized Structural Equation Modeling}}},
  shorttitle = {Regsem},
  author = {Jacobucci, Ross},
  year = {2017},
  month = sep,
  number = {arXiv:1703.08489},
  eprint = {1703.08489},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1703.08489},
  urldate = {2022-11-26},
  abstract = {The regsem package in R, an implementation of regularized structural equation modeling (RegSEM; Jacobucci, Grimm, and McArdle 2016), was recently developed with the goal of incorporating various forms of penalized likelihood estimation in a broad array of structural equations models. The forms of regularization include both the ridge (Hoerl and Kennard 1970) and the least absolute shrinkage and selection operator (lasso; Tibshirani 1996), along with sparser extensions. RegSEM is particularly useful for structural equation models that have a small parameter to sample size ratio, as the addition of penalties can reduce the complexity, thus reducing the bias of the parameter estimates. The paper covers the algorithmic details and an overview of the use of regsem with the application of both factor analysis and latent growth curve models.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {C\:\\Users\\fenn\\Zotero\\storage\\A65CAXTJ\\Jacobucci - 2017 - regsem Regularized Structural Equation Modeling.pdf;C\:\\Users\\fenn\\Zotero\\storage\\YNEK9TFS\\1703.html}
}

@article{jacobucciRegularizedStructuralEquation2016,
  title = {Regularized {{Structural Equation Modeling}}},
  author = {Jacobucci, Ross and Grimm, Kevin J. and McArdle, John J.},
  year = {2016},
  month = jul,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {23},
  number = {4},
  pages = {555--566},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2016.1154793},
  urldate = {2022-11-26},
  abstract = {A new method is proposed that extends the use of regularization in both lasso and ridge regression to structural equation models. The method is termed regularized structural equation modeling (RegSEM). RegSEM penalizes specific parameters in structural equation models, with the goal of creating easier to understand and simpler models. Although regularization has gained wide adoption in regression, very little has transferred to models with latent variables. By adding penalties to specific parameters in a structural equation model, researchers have a high level of flexibility in reducing model complexity, overcoming poor fitting models, and the creation of models that are more likely to generalize to new samples. The proposed method was evaluated through a simulation study, two illustrative examples involving a measurement model, and one empirical example involving the structural part of the model to demonstrate RegSEM's utility.},
  pmid = {27398019},
  keywords = {factor analysis,lasso,penalization,regularization,ridge,shrinkage,structural equation modeling},
  file = {C:\Users\fenn\Zotero\storage\RSNXPDQL\Jacobucci et al. - 2016 - Regularized Structural Equation Modeling.pdf}
}

@article{liTutorialUseRegsem2021,
  title = {Tutorial on the {{Use}} of the Regsem {{Package}} in {{R}}},
  author = {Li, Xiaobei and Jacobucci, Ross and Ammerman, Brooke A.},
  year = {2021},
  month = dec,
  journal = {Psych},
  volume = {3},
  number = {4},
  pages = {579--592},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2624-8611},
  doi = {10.3390/psych3040038},
  urldate = {2022-11-26},
  abstract = {Sparse estimation through regularization is gaining popularity in psychological research. Such techniques penalize the complexity of the model and could perform variable/path selection in an automatic way, and thus are particularly useful in models that have small parameter-to-sample-size ratios. This paper gives a detailed tutorial of the R package regsem, which implements regularization for structural equation models. Example R code is also provided to highlight the key arguments of implementing regularized structural equation models in this package. The tutorial ends by discussing remedies of some known drawbacks of a popular type of regularization, computational methods supported by the package that can improve the selection result, and some other practical issues such as dealing with missing data and categorical variables.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {latent variables,R,regularization,statistical learning,structural equation modeling},
  file = {C\:\\Users\\fenn\\Zotero\\storage\\PLT8JBBL\\Li et al. - 2021 - Tutorial on the Use of the regsem Package in R.pdf;C\:\\Users\\fenn\\Zotero\\storage\\ITUIDSN3\\38.html}
}

@article{yarkoniChoosingPredictionExplanation2017,
  title = {Choosing {{Prediction Over Explanation}} in {{Psychology}}: {{Lessons From Machine Learning}}},
  shorttitle = {Choosing {{Prediction Over Explanation}} in {{Psychology}}},
  author = {Yarkoni, Tal and Westfall, Jacob},
  year = {2017},
  month = nov,
  journal = {Perspectives on Psychological Science},
  volume = {12},
  number = {6},
  pages = {1100--1122},
  publisher = {SAGE Publications Inc},
  issn = {1745-6916},
  doi = {10.1177/1745691617693393},
  urldate = {2022-11-30},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology?s near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  langid = {english},
  file = {C:\Users\fenn\Zotero\storage\3SM3Q8SX\Yarkoni and Westfall - 2017 - Choosing Prediction Over Explanation in Psychology.pdf}
}

@book{pengArtDataScience2016,
  title = {The {{Art}} of {{Data Science}}: {{A Guide}} for {{Anyone}} Who {{Works}} with {{Data}}},
  shorttitle = {The {{Art}} of {{Data Science}}},
  author = {Peng, Roger D. and Matsui, Elizabeth},
  year = {2016},
  publisher = {Lulu.com},
  abstract = {This book describes, simply and in general terms, the process of analyzing data. The authors have extensive experience both managing data analysts and conducting their own data analyses, and have carefully observed what produces coherent results and what fails to produce useful insights into data. This book is a distillation of their experience in a format that is applicable to both practitioners and managers in data science.},
  googlebooks = {ZDH9DAEACAAJ},
  isbn = {978-1-365-06146-2},
  langid = {english},
  keywords = {Business & Economics / General},
  file = {C:\Users\fenn\Zotero\storage\SPZF6HSZ\Peng and Matsui - 2016 - The Art of Data Science A Guide for Anyone who Wo.pdf}
}
@article{leekWhatQuestion2015,
  title = {What Is the Question?},
  author = {Leek, Jeffery T. and Peng, Roger D.},
  year = {2015},
  month = mar,
  journal = {Science},
  volume = {347},
  number = {6228},
  pages = {1314--1315},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aaa6146},
  urldate = {2023-01-09},
  file = {C:\Users\fenn\Zotero\storage\C5ZDA9ZJ\Leek and Peng - 2015 - What is the question.pdf}
}

@article{rahalQualityResearchNeeds2023,
  title = {Quality Research Needs Good Working Conditions},
  author = {Rahal, Rima-Maria and Fiedler, Susann and Adetula, Adeyemi and Berntsson, Ronnie P.-A. and Dirnagl, Ulrich and Feld, Gordon B. and Fiebach, Christian J. and Himi, Samsad Afrin and Horner, Aidan J. and Lonsdorf, Tina B. and Sch{\"o}nbrodt, Felix and Silan, Miguel Alejandro A. and Wenzler, Michael and Azevedo, Fl{\'a}vio},
  year = {2023},
  month = feb,
  journal = {Nature Human Behaviour},
  volume = {7},
  number = {2},
  pages = {164--167},
  publisher = {Nature Publishing Group},
  issn = {2397-3374},
  doi = {10.1038/s41562-022-01508-2},
  urldate = {2023-03-31},
  abstract = {High-quality research requires appropriate employment and working conditions for researchers. However, many academic systems rely on short-term employment contracts, biased selection procedures and misaligned incentives, which hinder research quality and progress. We discuss ways to redesign academic systems, emphasizing the role of permanent employment.},
  copyright = {2023 Springer Nature Limited},
  langid = {english},
  keywords = {Careers,Policy}
}
@book{konsortiumbundesberichtwissenschaftlichernachwuchsBundesberichtWissenschaftlicherNachwuchs2021,
  title = {{Bundesbericht Wissenschaftlicher Nachwuchs 2021}},
  author = {{Konsortium Bundesbericht Wissenschaftlicher Nachwuchs}},
  year = {2021},
  month = feb,
  publisher = {wbv Media},
  address = {DE},
  urldate = {2023-03-31},
  isbn = {978-3-7639-6008-8},
  langid = {ngerman},
  file = {C:\Users\fenn\Zotero\storage\UL9ECXAB\Konsortium Bundesbericht Wissenschaftlicher Nachwuchs - 2021 - Bundesbericht Wissenschaftlicher Nachwuchs 2021.pdf}
}
@article{sengewaldFamiliengerechteKarrieremoglichkeitenPsychologischen2024,
  title = {Familiengerechte {{Karrierem{\"o}glichkeiten}} in Der~Psychologischen {{Forschung}}?},
  author = {Sengewald, Marie-Ann and Henninger, Mirka and Bechtloff, Pia and Kubik, Veit},
  year = {2024},
  month = jul,
  journal = {Psychologische Rundschau},
  volume = {75},
  number = {3},
  pages = {236--248},
  publisher = {Hogrefe Verlag},
  issn = {0033-3042},
  doi = {10.1026/0033-3042/a000682},
  urldate = {2024-10-18}
}
@book{wallersteinEuropeanUniversalismRhetoric2006,
  title = {European {{Universalism}}: {{The Rhetoric}} of {{Power}}},
  shorttitle = {European {{Universalism}}},
  author = {Wallerstein, Immanuel Maurice},
  year = {2006},
  month = jan,
  publisher = {New Press},
  abstract = {How ideas such as civilization and progress have been used as a smoke screen for western dominance, by the world-renowned sociologist. Ever since the Enlightenment, Western intervention around the world has been justified by appeals to notions of civilization, development, and progress. The assumption has been that such ideas are universal, encrusted in natural law. But, as Immanuel Wallerstein argues in this short and elegant philippic, these concepts are, in fact, not global. Rather, their genesis is firmly rooted in European thought and their primary function has been to provide justification for powerful states to impose their will against the weak under the smoke screen of what is supposed to be both beneficial to humankind and historically inevitable. With great acuity Wallerstein draws together discussions of the idea of orientalism, the right to intervene, and the triumph of science over the humanities to explain how strategies designed to promote particular Western interests have acquired an all-inclusive patina. Wallerstein concludes by advocating a true universalism that will allow critical appraisal of all justifications for intervention by the powerful against the weak. At a time when such intervention--in the name of democracy and human rights--has returned to the center stage of world politics, his treatise is both relevant and compelling.},
  googlebooks = {2Kju1wtsyGoC},
  isbn = {978-1-59558-061-0},
  langid = {english},
  keywords = {Social Science / Sociology / General}
}
@book{fligsteinTheoryFields2015,
  title = {A {{Theory}} of {{Fields}}},
  author = {Fligstein, Neil and McAdam, Doug},
  year = {2015},
  publisher = {Oxford University Press},
  abstract = {Finding ways to understand the nature of social change and social order-from political movements to market meltdowns-is one of the enduring problems of social science. A Theory of Fields draws together far-ranging insights from social movement theory, organizational theory, and economic and political sociology to construct a general theory of social organization and strategic action. In a work of remarkable synthesis, imagination, and analysis, Neil Fligstein and Doug McAdam propose that social change and social order can be understood through what they call strategic action fields. They posit that these fields are the general building blocks of political and economic life, civil society, and the state, and the fundamental form of order in our world today. Similar to Russian dolls, they are nested and connected in a broader environment of almost countless proximate and overlapping fields. Fields are mutually dependent; change in one often triggers change in another. At the core of the theory is an account of how social actors fashion and maintain order in a given field. This sociological theory of action, what they call "social skill," helps explain what individuals do in strategic action fields to gain cooperation or engage in competition. To demonstrate the breadth of the theory, Fligstein and McAdam make its abstract principles concrete through extended case studies of the Civil Rights Movement and the rise and fall of the market for mortgages in the U.S. since the 1960s. The book also provides a "how-to" guide to help others implement the approach and discusses methodological issues. With a bold new approach, A Theory of Fields offers both a rigorous and practically applicable way of thinking through and making sense of social order and change-and how one emerges from the other-in modern, complex societies.},
  googlebooks = {I3I8DwAAQBAJ},
  isbn = {978-0-19-024145-2},
  langid = {english},
  keywords = {Social Science / Methodology},
  file = {C:\Users\fenn\Zotero\storage\Q3R2MPC2\Fligstein and McAdam - 2015 - A Theory of Fields.pdf}
}
@book{luhmannSozialeSystemeGrundriss1987,
  title = {Soziale {{Systeme}}: {{Grundriss}} Einer Allgemeinen {{Theorie}}},
  author = {Luhmann, Niklas},
  year = {1987},
  publisher = {Suhrkamp},
  abstract = {Niklas Luhmann versucht, {\"u}ber den Diskussionsstand in der Soziologie hinauszuf{\"u}hren. Er geht davon aus, da{\ss} ein Paradigmawechsel in der allgemeinen Systemtheorie auch f{\"u}r die Theorie sozialer Systeme neue Chancen er{\"o}ffnet und die {\"u}blichen Einw{\"a}nde gegen einen >>technologischen<< Einsatz des Systembegriffs ausr{\"a}umt. Das Buch versucht, eine begriffliche Komplexit{\"a}t und Interdependenz mit den Mitteln der normalen Sprache darzustellen. Die Einheit der Theorie liegt in der Abgestimmtheit einer gro{\ss}en Zahl von Begriffsentscheidungen, die zum Teil im R{\"u}ckblick auf die soziologische Tradition und zum Teil im Anschlu{\ss} an Vorgaben aus der Kybernetik, der Biologie, der Kommunikationstheorie und der Evolutionstheorie gewonnen sind. Luhmann sieht in diesem Kombinationsversuch eine wesentliche Voraussetzung f{\"u}r weitere Arbeiten an einer Theorie der modernen Gesellschaft.},
  isbn = {3-518-28266-2}
}
@book{tourangeauPsychologySurveyResponse2000,
  title = {The {{Psychology}} of {{Survey Response}}},
  author = {Tourangeau, Roger and Rips, Lance J. and Rasinski, Kenneth},
  year = {2000},
  month = mar,
  publisher = {Cambridge University Press},
  abstract = {This valuable book examines the complex psychological processes involved in answering different types of survey questions. Drawing on both classic and modern research from cognitive psychology, social psychology, and survey methodology, the authors examine how survey responses are formulated and they demonstrate how seemingly unimportant features of the survey can affect the answers obtained. The book provides a comprehensive review of the sources of response errors in surveys, and it offers a coherent theory of the relation between the underlying views of the public and the results of public opinion polls. Topics include the comprehension of survey questions, the recall of relevant facts and beliefs, estimation and inferential processes people use to answer survey questions, the sources of the apparent instability of public opinion, the difficulties in getting responses into the required format, and the distortions introduced into surveys by deliberate misreporting.},
  googlebooks = {bjVYdyXXT3oC},
  isbn = {978-0-521-57629-1},
  langid = {english},
  keywords = {Language Arts & Disciplines / Communication Studies,Psychology / Research & Methodology,Psychology / Social Psychology,Social Science / Methodology},
  file = {C:\Users\fenn\Zotero\storage\T57JR5JT\Tourangeau et al. - 2000 - The Psychology of Survey Response.pdf}
}
@book{moosbruggerTesttheorieUndFragebogenkonstruktion2020,
  title = {{Testtheorie und Fragebogenkonstruktion}},
  editor = {Moosbrugger, Helfried and Kelava, Augustin},
  year = {2020},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-61532-4},
  urldate = {2022-07-08},
  isbn = {978-3-662-61531-7},
  langid = {ngerman},
  file = {C:\Users\fenn\Zotero\storage\WDUTXUIP\Moosbrugger and Kelava - 2020 - Testtheorie und Fragebogenkonstruktion.pdf}
}

@phdthesis{schurigLatenteVariablenmodelleEmpirischen2017,
  title = {{Latente Variablenmodelle in der empirischen Bildungsforschung - die Sch{\"a}rfe und Struktur der Schatten an der Wand}},
  author = {Schurig, Michael},
  year = {2017},
  urldate = {2022-12-06},
  abstract = {Diese Arbeit tr{\"a}gt theoretische Annahmen zu latenten Variablen in verschiedenen g{\"a}ngigen Ableitungsformen zusammen und verkn{\"u}pft diese mit den Grundannahmen der Mess- und Testtheorie sowie den Bedingungen zur Verwendung quantitativ empirischer Ergebnisse als Evidenzform f{\"u}r die Beobachtung stochastisch kausaler Zusammenh{\"a}nge. Hierzu werden die Hauptg{\"u}tekriterien von Tests und Messungen sowie deren Bedeutung f{\"u}r latente Variablenmodelle diskutiert und mit Strategien der Modellevaluation verkn{\"u}pft. Dabei wird insbesondere die Versprachlichung formaler Definitionen angestrebt, um die impliziten Charakteristika der Verfahren, welche in der Anwendung eine gewichtige Relevanz haben, herauszustellen und so einen reflektierten und passgenauen Einsatz dieser statistischen Modelltypen zu vereinfachen. Damit richtet sich diese Arbeit insbesondere an Anwender latenter Variablenmodelle in einem geisteswissenschaftlichen Kontext. Daf{\"u}r wird zuerst die Bedeutung statistischer Modelle mit latenten Variablen in den Bildungswissenschaften ausgef{\"u}hrt (Kap. 2) und in der Folge werden Theorien zur Definition latenter Variablen vorgestellt (Kap. 3). Es wird argumentiert, dass die verbreiteten Alltagsdefinitionen nicht ausreichend sind, und es wird ein definitorischer Rahmen vorgestellt, der sowohl eine theoretische als auch formale Ankn{\"u}pfung erlaubt. Zudem werden verschiedene zentrale Modelltypen, deren Eigenschaften sowie eine generalisierte Betrachtungsweise kurz umrissen (Kap.3.1). Die Basis f{\"u}r die Verkn{\"u}pfung statistischer Modelle und deren theoretischen Annahmen bilden die Mess- und Testtheorie. Die impliziten Annahmen und deren Implikationen werden in Kapitel 3.2 herausgestellt. Sofern eine theoretische Verkn{\"u}pfung und eine Modellbildung gelungen ist, k{\"o}nnen Evidenzen angesammelt werden, {\"u}ber die auf vorl{\"a}ufige stochastische Kausalit{\"a}t geschlossen werden kann (Kap. 3.3). Zur Bewertung vorliegender Evidenz sind wissenschaftliche Normen und Standards von Bedeutung. Dazu werden die Hauptg{\"u}tekriterien wissenschaftlicher Tests und Messungen (Kap. 4) besprochen und deren Anwendbarkeit und Pr{\"u}fbarkeit f{\"u}r latente Variablenmodelle ausgef{\"u}hrt. In der Folge werden Strategien der Modellidentifikation und -evaluation sowie implizite Anwendungsprobleme und Anwendungsl{\"o}sungen mit einzelnen Strategien zusammengefasst (Kap. 5). Erg{\"a}nzend werden Einsch{\"a}tzungen zu Strategien der Modellevaluation gegeben und ein Raster von Modellg{\"u}tebeurteilungen vorgestellt (Kap. 5.3). Als Rahmung f{\"u}r verschiedene Artikel, die auf die substanzwissenschaftliche Anwendung von latenten Variablenmodellen fokussieren (vgl. Anhang 2), werden in dieser Arbeit die gemeinsamen Grundlegungen zu diesen zusammengetragen und expliziert, w{\"a}hrend die Artikel exemplarisch verwendet werden, um die praktische Anwendung von Prinzipien zu verdeutlichen.},
  langid = {ngerman},
  school = {TU Dortmund},
  annotation = {Accepted: 2017-07-17T08:39:54Z},
  file = {C\:\\Users\\fenn\\Zotero\\storage\\MWAQMH3Y\\Schurig - 2017 - Latente Variablenmodelle in der empirischen Bildun.pdf;C\:\\Users\\fenn\\Zotero\\storage\\HINNTU6C\\36026.html}
}

@article{borsboomLatentVariableTheory2008,
  title = {Latent {{Variable Theory}}},
  author = {Borsboom, Denny},
  year = {2008},
  month = may,
  journal = {Measurement: Interdisciplinary Research and Perspectives},
  volume = {6},
  number = {1-2},
  pages = {25--53},
  publisher = {Routledge},
  issn = {1536-6367},
  doi = {10.1080/15366360802035497},
  urldate = {2022-12-06},
  abstract = {This paper formulates a metatheoretical framework for latent variable modeling. It does so by spelling out the difference between observed and latent variables. This difference is argued to be purely epistemic in nature: We treat a variable as observed when the inference from data structure to variable structure can be made with certainty and as latent when this inference is prone to error. This difference in epistemic accessibility is argued to be directly related to the data-generating process, i.e., the process that produces the concrete data patterns on which statistical analyses are executed. For a variable to count as observed through a set of data patterns, the relation between variable structure and data structure should be (a) deterministic, (b) causally isolated, and (c) of equivalent cardinality. When any of these requirements is violated, (part of) the variable structure should be considered latent. It is argued that, on these criteria, observed variables are rare to nonexistent in psychology; hence, psychological variables should be considered latent until proven observed.},
  keywords = {latent variables,measurement theory,philosophy of science,psychometrics,test theory},
  file = {C:\Users\fenn\Zotero\storage\ZP6DZT9A\Borsboom - 2008 - Latent Variable Theory.pdf}
}

@article{skrondalLatentVariableModelling2007,
  title = {Latent {{Variable Modelling}}: {{A Survey}}*},
  shorttitle = {Latent {{Variable Modelling}}},
  author = {Skrondal, Anders and {Rabe-Hesketh}, Sophia},
  year = {2007},
  journal = {Scandinavian Journal of Statistics},
  volume = {34},
  number = {4},
  pages = {712--745},
  issn = {1467-9469},
  doi = {10.1111/j.1467-9469.2007.00573.x},
  urldate = {2022-12-06},
  abstract = {Abstract. Latent variable modelling has gradually become an integral part of mainstream statistics and is currently used for a multitude of applications in different subject areas. Examples of `traditional' latent variable models include latent class models, item--response models, common factor models, structural equation models, mixed or random effects models and covariate measurement error models. Although latent variables have widely different interpretations in different settings, the models have a very similar mathematical structure. This has been the impetus for the formulation of general modelling frameworks which accommodate a wide range of models. Recent developments include multilevel structural equation models with both continuous and discrete latent variables, multiprocess models and nonlinear latent variable models.},
  langid = {english},
  keywords = {factor analysis,GLLAMM,item-response theory,latent class,latent trait,latent variable,measurement error,mixed effects model,multilevel model,random effect,structural equation model},
  file = {C\:\\Users\\fenn\\Zotero\\storage\\D9IS33HK\\Skrondal and Rabe-Hesketh - 2007 - Latent Variable Modelling A Survey.pdf;C\:\\Users\\fenn\\Zotero\\storage\\SK6SQXFV\\j.1467-9469.2007.00573.html}
}

@book{skrondalGeneralizedLatentVariable2004,
  title = {Generalized {{Latent Variable Modeling}}: {{Multilevel}}, {{Longitudinal}}, and {{Structural Equation Models}}},
  author = {Skrondal, Anders and {Rabe-Hesketh}, Sophia},
  year = {2004},
  month = may,
  publisher = {{Chapman and Hall/CRC}},
  address = {New York},
  doi = {10.1201/9780203489437},
  abstract = {This book unifies and extends latent variable models, including multilevel or generalized linear mixed models, longitudinal or panel models, item response or factor models, latent class or finite mixture models, and structural equation models. Following a gentle introduction to latent variable modeling, the authors clearly explain and contrast a wi},
  isbn = {978-0-429-20549-1},
  file = {C:\Users\fenn\Zotero\storage\HL4HSYWZ\Skrondal and Rabe-Hesketh - 2004 - Generalized Latent Variable Modeling Multilevel, .pdf}
}
@article{bollenLatentVariablesPsychology2002,
  title = {Latent Variables in Psychology and the Social Sciences},
  author = {Bollen, Kenneth A},
  year = {2002},
  month = jan,
  journal = {Annual review of psychology},
  volume = {53},
  pages = {605--634},
  issn = {1545-2085},
  doi = {10.1146/annurev.psych.53.100901.135239},
  urldate = {2022-12-06},
  abstract = {The paper discusses the use of latent variables in psychology and social science research. Local independence, expected value true scores, and nondeterministic functions of observed variables are three types of definitions for latent variables. These definitions are reviewed and an alternative "sample realizations" definition is presented. Another section briefly describes identification, latent variable indeterminancy, and other properties common to models with latent variables. The paper then reviews the role of latent variables in multiple regression, probit and logistic regression, factor analysis, latent curve models, item response theory, latent class analysis, and structural equation models. Though these application areas are diverse, the paper highlights the similarities as well as the differences in the manner in which the latent variables are defined and used. It concludes with an evaluation of the different definitions of latent variables and their properties.},
  langid = {english},
  pmid = {11752498},
  file = {C:\Users\fenn\Zotero\storage\TVM953PT\Bollen - 2002 - Latent variables in psychology and the social scie.pdf}
}
@article{cronbachConstructValidityPsychological1955,
  title = {Construct Validity in Psychological Tests},
  author = {Cronbach, Lee J. and Meehl, Paul E.},
  year = {1955},
  journal = {Psychological Bulletin},
  volume = {52},
  number = {4},
  pages = {281--302},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/h0040957},
  abstract = {"Construct validation was introduced in order to specify types of research required in developing tests for which the conventional views on validation are inappropriate. Personality tests, and some tests of ability, are interpreted in terms of attributes for which there is no adequate criterion. This paper indicates what sorts of evidence can substantiate such an interpretation, and how such evidence is to be interpreted." 60 references. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Construct Validity,Personality Measures,Psychometrics,Test Validity},
  file = {C\:\\Users\\fenn\\Zotero\\storage\\EHD6SY45\\Cronbach and Meehl - 1955 - Construct validity in psychological tests.pdf;C\:\\Users\\fenn\\Zotero\\storage\\J9RIADGH\\Cronbach and Meehl - 1955 - Construct validity in psychological tests.pdf;C\:\\Users\\fenn\\Zotero\\storage\\2WM2NPN8\\1956-03730-001.html}
}
@book{biemerTotalSurveyError2017,
  title = {Total {{Survey Error}} in {{Practice}}},
  author = {Biemer, Paul P. and de Leeuw, Edith D. and Eckman, Stephanie and Edwards, Brad and Kreuter, Frauke and Lyberg, Lars E. and Tucker, N. Clyde and West, Brady T.},
  year = {2017},
  month = feb,
  publisher = {John Wiley \& Sons},
  abstract = {Featuring a timely presentation of total survey error (TSE), this edited volume introduces valuable tools for understanding and improving survey data quality in the context of evolving large-scale data sets This book provides an overview of the TSE framework and current TSE research as related to survey design, data collection, estimation, and analysis. It recognizes that survey data affects many public policy and business decisions and thus focuses on the framework for understanding and improving survey data quality. The book also addresses issues with data quality in official statistics and in social, opinion, and market research as these fields continue to evolve, leading to larger and messier data sets. This perspective challenges survey organizations to find ways to collect and process data more efficiently without sacrificing quality. The volume consists of the most up-to-date research and reporting from over 70 contributors representing the best academics and researchers from a range of fields. The chapters are broken out into five main sections: The Concept of TSE and the TSE Paradigm, Implications for Survey Design, Data Collection and Data Processing Applications, Evaluation and Improvement, and Estimation and Analysis. Each chapter introduces and examines multiple error sources, such as sampling error, measurement error, and nonresponse error, which often offer the greatest risks to data quality, while also encouraging readers not to lose sight of the less commonly studied error sources, such as coverage error, processing error, and specification error. The book also notes the relationships between errors and the ways in which efforts to reduce one type can increase another, resulting in an estimate with larger total error. This book: {$\bullet$} Features various error sources, and the complex relationships between them, in 25 high-quality chapters on the most up-to-date research in the field of TSE {$\bullet$} Provides comprehensive reviews of the literature on error sources as well as data collection approaches and estimation methods to reduce their effects {$\bullet$} Presents examples of recent international events that demonstrate the effects of data error, the importance of survey data quality, and the real-world issues that arise from these errors {$\bullet$} Spans the four pillars of the total survey error paradigm (design, data collection, evaluation and analysis) to address key data quality issues in official statistics and survey research Total Survey Error in Practice is a reference for survey researchers and data scientists in research areas that include social science, public opinion, public policy, and business. It can also be used as a textbook or supplementary material for a graduate-level course in survey research methods.},
  googlebooks = {M\_8fDgAAQBAJ},
  isbn = {978-1-119-04169-6},
  langid = {english},
  keywords = {Mathematics / General,Mathematics / Probability & Statistics / Stochastic Processes,Psychology / Research & Methodology,Social Science / Methodology,Social Science / Statistics}
}

@article{grovesTotalSurveyError2010,
  title = {Total {{Survey Error}}: {{Past}}, {{Present}}, and {{Future}}},
  shorttitle = {Total {{Survey Error}}},
  author = {Groves, Robert M. and Lyberg, Lars},
  year = {2010},
  month = jan,
  journal = {Public Opinion Quarterly},
  volume = {74},
  number = {5},
  pages = {849--879},
  issn = {0033-362X},
  doi = {10.1093/poq/nfq065},
  urldate = {2023-04-18},
  abstract = {``Total survey error'' is a conceptual framework describing statistical error properties of sample survey statistics. Early in the history of sample surveys, it arose as a tool to focus on implications of various gaps between the conditions under which probability samples yielded unbiased estimates of finite population parameters and practical situations in implementing survey design. While the framework permits design-based estimates of various error components, many of the design burdens to produce those estimates are large, and in practice most surveys do not implement them. Further, the framework does not incorporate other, nonstatistical, dimensions of quality that are commonly utilized in evaluating statistical information. The importation of new modeling tools brings new promise to measuring total survey error components, but also new challenges. A lasting value of the total survey error framework is at the design stage of a survey, to attempt a balance of costs and various errors. Indeed, this framework is the central organizing structure of the field of survey methodology.},
  file = {C\:\\Users\\fenn\\Zotero\\storage\\BPRWHAWJ\\Groves and Lyberg - 2010 - Total Survey Error Past, Present, and Future.pdf;C\:\\Users\\fenn\\Zotero\\storage\\P5F8NGT3\\1817502.html}
}
@article{auerswaldHowDetermineNumber2019,
  title = {How to Determine the Number of Factors to Retain in Exploratory Factor Analysis: {{A}} Comparison of Extraction Methods under Realistic Conditions},
  shorttitle = {How to Determine the Number of Factors to Retain in Exploratory Factor Analysis},
  author = {Auerswald, Max and Moshagen, Morten},
  year = {2019},
  journal = {Psychological Methods},
  volume = {24},
  pages = {468--491},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1463},
  doi = {10.1037/met0000200},
  abstract = {Exploratory factor analyses are commonly used to determine the underlying factors of multiple observed variables. Many criteria have been suggested to determine how many factors should be retained. In this study, we present an extensive Monte Carlo simulation to investigate the performance of extraction criteria under varying sample sizes, numbers of indicators per factor, loading magnitudes, underlying multivariate distributions of observed variables, as well as how the performance of the extraction criteria are influenced by the presence of cross-loadings and minor factors for unidimensional, orthogonal, and correlated factor models. We compared several variants of traditional parallel analysis (PA), the Kaiser-Guttman Criterion, and sequential {$\chi$}2 model tests (SMT) with 4 recently suggested methods: revised PA, comparison data (CD), the Hull method, and the Empirical Kaiser Criterion (EKC). No single extraction criterion performed best for every factor model. In unidimensional and orthogonal models, traditional PA, EKC, and Hull consistently displayed high hit rates even in small samples. Models with correlated factors were more challenging, where CD and SMT outperformed other methods, especially for shorter scales. Whereas the presence of cross-loadings generally increased accuracy, non-normality had virtually no effect on most criteria. We suggest researchers use a combination of SMT and either Hull, the EKC, or traditional PA, because the number of factors was almost always correctly retrieved if those methods converged. When the results of this combination rule are inconclusive, traditional PA, CD, and the EKC performed comparatively well. However, disagreement also suggests that factors will be harder to detect, increasing sample size requirements to N {$\geq$} 500. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Exploratory Factor Analysis,Factor Analysis,Sample Size,Simulation},
  file = {C:\Users\fenn\Zotero\storage\5A4PKCLW\Auerswald and Moshagen - 2019 - How to determine the number of factors to retain i.pdf}
}

@Comment{jabref-meta: databaseType:bibtex;}
